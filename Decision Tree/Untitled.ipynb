{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gprof2dot in /Users/yaoliang/opt/anaconda3/lib/python3.7/site-packages (2021.2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gprof2dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading https://files.pythonhosted.org/packages/86/86/89ba50ba65928001d3161f23bfa03945ed18ea13a1d1d44a772ff1fa4e7a/graphviz-0.16-py2.py3-none-any.whl\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.16\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to install \"gprof2dot\"\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "import sklearn.tree\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "random.seed(246810)\n",
    "np.random.seed(246810)\n",
    "\n",
    "eps = 1e-5  # a small number\n",
    "\n",
    "\n",
    "# Vectorized function for hashing for np efficiency\n",
    "def w(x):\n",
    "    return np.int(hash(x)) % 1000\n",
    "\n",
    "\n",
    "h = np.vectorize(w)\n",
    "\n",
    "\n",
    "class DecisionTree():\n",
    "    def __init__(self, max_depth=3, feature_labels=None, rf=False, num_features=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.features = feature_labels\n",
    "        self.left, self.right = None, None  # for non-leaf nodes\n",
    "        self.split_idx, self.thresh = None, None  # for non-leaf nodes\n",
    "        self.data, self.pred = None, None  # for leaf nodes\n",
    "        self.rf = rf\n",
    "        self.num_features = num_features\n",
    "    \n",
    "    def __repr__(self, depth = 0, left = 'top'):\n",
    "        if self.pred is not None:\n",
    "            print(\" \" * depth * 2 + left + ' '+ 'class: ' + str(self.pred))\n",
    "        else:\n",
    "            print(\" \" * depth * 2 + left + ' ' + 'feature name: ' + str(self.features[self.split_idx]) + ' ' + \"split thresh: <\" + str(self.thresh))\n",
    "            self.right.__repr__(depth + 1, 'right')\n",
    "            self.left.__repr__(depth + 1, 'left')\n",
    "\n",
    "    @staticmethod\n",
    "    def information_gain(X, y, thresh):\n",
    "        # TODO implement information gain function\n",
    "        if y.size == 0:\n",
    "            hs = 0\n",
    "        else:\n",
    "            p = sum(y < 0.5)/len(y)\n",
    "            if p == 0 or p == 1:\n",
    "                hs = 0\n",
    "            else:\n",
    "                hs = -p * np.log(p) - (1 - p) * np.log(1 - p)\n",
    "        s1 = y[X < thresh]\n",
    "        s2 = y[X >= thresh]\n",
    "        if s1.size == 0:\n",
    "            hsl = 0\n",
    "        else:\n",
    "            p = sum(s1 < 0.5)/len(s1)\n",
    "            if p == 0 or p == 1:\n",
    "                hsl = 0\n",
    "            else:\n",
    "                hsl = -p * np.log(p) - (1 - p) * np.log(1 - p)\n",
    "        if s2.size == 0:\n",
    "            hsr = 0\n",
    "        else:\n",
    "            p = sum(s2 < 0.5)/len(s2)\n",
    "            if p == 0 or p == 1:\n",
    "                hsr = 0\n",
    "            else:\n",
    "                hsr = -p * np.log(p) - (1 - p) * np.log(1 - p)\n",
    "        p = len(s1)/len(y)\n",
    "        return hs - (p * hsl + (1 - p) * hsr)\n",
    "\n",
    "    @staticmethod\n",
    "    def gini_impurity(X, y, thresh):\n",
    "        # TODO implement gini_impurity function\n",
    "        if y.size == 0:\n",
    "            hs = 0\n",
    "        else:\n",
    "            p = sum(y < 0.5)/len(y)\n",
    "            hs = p * (1 - p) + (1 - p) * p\n",
    "        s1 = y[X < thresh]\n",
    "        s2 = y[X >= thresh]\n",
    "        if s1.size == 0:\n",
    "            hsl = 0\n",
    "        else:\n",
    "            p = sum(s1 < 0.5)/len(s1)\n",
    "            hsl = p * (1 - p) + (1 - p) * p\n",
    "        if s2.size == 0:\n",
    "            hsr = 0\n",
    "        else:\n",
    "            p = sum(s2 < 0.5)/len(s2)\n",
    "            hsr = p * (1 - p) + (1 - p) * p\n",
    "        p = len(s1)/len(y)\n",
    "        return hs - (p * hsl + (1 - p) * hsr)\n",
    "\n",
    "    def split(self, X, y, idx, thresh):\n",
    "        X0, idx0, X1, idx1 = self.split_test(X, idx=idx, thresh=thresh)\n",
    "        y0, y1 = y[idx0], y[idx1]\n",
    "        return X0, y0, X1, y1\n",
    "\n",
    "    def split_test(self, X, idx, thresh):\n",
    "        idx0 = np.where(X[:, idx] < thresh)[0]\n",
    "        idx1 = np.where(X[:, idx] >= thresh)[0]\n",
    "        X0, X1 = X[idx0, :], X[idx1, :]\n",
    "        return X0, idx0, X1, idx1\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.max_depth > 0:\n",
    "            # compute entropy gain for all single-dimension splits,\n",
    "            # thresholding with a linear interpolation of 10 values\n",
    "            gains = []\n",
    "            # The following logic prevents thresholding on exactly the minimum\n",
    "            # or maximum values, which may not lead to any meaningful node\n",
    "            # splits.\n",
    "            if self.rf != True:\n",
    "                thresh = np.array([\n",
    "                    np.linspace(np.min(X[:, i]) + eps, np.max(X[:, i]) - eps, num=10)\n",
    "                    for i in range(X.shape[1])\n",
    "                ])\n",
    "                for i in range(X.shape[1]):\n",
    "                    gains.append([self.information_gain(X[:, i], y, t) for t in thresh[i, :]])\n",
    "\n",
    "                gains = np.nan_to_num(np.array(gains))\n",
    "                self.split_idx, thresh_idx = np.unravel_index(np.argmax(gains), gains.shape)\n",
    "                self.thresh = thresh[self.split_idx, thresh_idx]\n",
    "            else:\n",
    "                index = np.random.choice(X.shape[1], self.num_features, replace=False)\n",
    "                index.sort()\n",
    "                thresh = np.array([\n",
    "                    np.linspace(np.min(X[:, index][:, i]) + eps, np.max(X[:, index][:, i]) - eps, num=10)\n",
    "                    for i in range(X[:, index].shape[1])\n",
    "                ])\n",
    "                for i in range(X[:, index].shape[1]):\n",
    "                    gains.append([self.information_gain(X[:, index][:, i], y, t) for t in thresh[i, :]])\n",
    "\n",
    "                gains = np.nan_to_num(np.array(gains))\n",
    "                self.split_idx, thresh_idx = np.unravel_index(np.argmax(gains), gains.shape)\n",
    "                self.thresh = thresh[self.split_idx, thresh_idx]\n",
    "            X0, y0, X1, y1 = self.split(X, y, idx=self.split_idx, thresh=self.thresh)\n",
    "            if X0.size > 0 and X1.size > 0:\n",
    "                self.left = DecisionTree(\n",
    "                    max_depth=self.max_depth - 1, feature_labels=self.features)\n",
    "                self.left.fit(X0, y0)\n",
    "                self.right = DecisionTree(\n",
    "                    max_depth=self.max_depth - 1, feature_labels=self.features)\n",
    "                self.right.fit(X1, y1)\n",
    "            else:\n",
    "                self.max_depth = 0\n",
    "                self.data, self.labels = X, y\n",
    "                self.pred = stats.mode(y).mode[0]\n",
    "        else:\n",
    "            self.data, self.labels = X, y\n",
    "            self.pred = stats.mode(y).mode[0]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.max_depth == 0:\n",
    "            return self.pred * np.ones(X.shape[0])\n",
    "        else:\n",
    "            X0, idx0, X1, idx1 = self.split_test(X, idx=self.split_idx, thresh=self.thresh)\n",
    "            yhat = np.zeros(X.shape[0])\n",
    "            yhat[idx0] = self.left.predict(X0)\n",
    "            yhat[idx1] = self.right.predict(X1)\n",
    "            return yhat\n",
    "\n",
    "\n",
    "class BaggedTrees(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, params=None, n=200, feature_labels=None):\n",
    "        if params is None:\n",
    "            params = {}\n",
    "        self.params = params\n",
    "        self.n = n\n",
    "        self.decision_trees = [\n",
    "            DecisionTree(max_depth = self.params['max_depth'], feature_labels = feature_labels)\n",
    "            for i in range(self.n)\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # TODO implement function\n",
    "        for i in range(self.n):\n",
    "            index = np.random.choice(X.shape[0], X.shape[0])\n",
    "            self.decision_trees[i].fit(X[index], y[index])\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO implement function\n",
    "        total = []\n",
    "        for i in range(self.n):\n",
    "            total += [self.decision_trees[i].predict(X)]\n",
    "        return np.round(np.mean(total, axis=0))\n",
    "\n",
    "\n",
    "class RandomForest(BaggedTrees):\n",
    "    def __init__(self, params=None, n=200, m=1, feature_labels=None):\n",
    "        BaggedTrees.__init__(self = self, params = params, n = n, feature_labels = feature_labels)\n",
    "        for i in self.decision_trees:\n",
    "            i.num_features = m\n",
    "            i.rf = True\n",
    "\n",
    "# You do not have to implement the following boost part, though it might help with Kaggle.\n",
    "class BoostedRandomForest(RandomForest):\n",
    "    def fit(self, X, y):\n",
    "        self.w = np.ones(X.shape[0]) / X.shape[0]  # Weights on data\n",
    "        self.a = np.zeros(self.n)  # Weights on decision trees\n",
    "        # TODO implement function\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO implement function\n",
    "        pass\n",
    "\n",
    "\n",
    "def preprocess(data, fill_mode=True, min_freq=10, onehot_cols=[]):\n",
    "    # fill_mode = False\n",
    "\n",
    "    # Temporarily assign -1 to missing data\n",
    "    data[data == b''] = '-1'\n",
    "\n",
    "    # Hash the columns (used for handling strings)\n",
    "    onehot_encoding = []\n",
    "    onehot_features = []\n",
    "    for col in onehot_cols:\n",
    "        counter = Counter(data[:, col])\n",
    "        for term in counter.most_common():\n",
    "            if term[0] == b'-1':\n",
    "                continue\n",
    "            if term[-1] <= min_freq:\n",
    "                break\n",
    "            onehot_features.append(term[0])\n",
    "            onehot_encoding.append((data[:, col] == term[0]).astype(np.float))\n",
    "        data[:, col] = '0'\n",
    "    onehot_encoding = np.array(onehot_encoding).T\n",
    "    data = np.hstack([np.array(data, dtype=np.float), np.array(onehot_encoding)])\n",
    "\n",
    "    # Replace missing data with the mode value. We use the mode instead of\n",
    "    # the mean or median because this makes more sense for categorical\n",
    "    # features such as gender or cabin type, which are not ordered.\n",
    "    if fill_mode:\n",
    "        for i in range(data.shape[-1]):\n",
    "            mode = stats.mode(data[((data[:, i] < -1 - eps) +\n",
    "                                    (data[:, i] > -1 + eps))][:, i]).mode[0]\n",
    "            data[(data[:, i] > -1 - eps) * (data[:, i] < -1 + eps)][:, i] = mode\n",
    "\n",
    "    return data, onehot_features\n",
    "\n",
    "\n",
    "def evaluate(clf):\n",
    "    print(\"Cross validation:\")\n",
    "    cv_results = cross_validate(clf, X, y, cv=5, return_train_score=True)\n",
    "    train_results = cv_results['train_score']\n",
    "    test_results = cv_results['test_score']\n",
    "    avg_train_accuracy = sum(train_results) / len(train_results)\n",
    "    avg_test_accuracy = sum(test_results) / len(test_results)\n",
    "\n",
    "    print('averaged train accuracy:', avg_train_accuracy)\n",
    "    print('averaged validation accuracy:', avg_test_accuracy)\n",
    "    if hasattr(clf, \"decision_trees\"):\n",
    "        counter = Counter([t.tree_.feature[0] for t in clf.decision_trees])\n",
    "        first_splits = [\n",
    "            (features[term[0]], term[1]) for term in counter.most_common()\n",
    "        ]\n",
    "        print(\"First splits\", first_splits)\n",
    "\n",
    "    return avg_train_accuracy, avg_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features ['pain', 'private', 'bank', 'money', 'drug', 'spam', 'prescription', 'creative', 'height', 'featured', 'differ', 'width', 'other', 'energy', 'business', 'message', 'volumes', 'revision', 'path', 'meter', 'memo', 'planning', 'pleased', 'record', 'out', 'semicolon', 'dollar', 'sharp', 'exclamation', 'parenthesis', 'square_bracket', 'ampersand']\n",
      "Train/test size (5172, 32) (5857, 32)\n",
      "\n",
      "\n",
      "Part 0: constant classifier\n",
      "Accuracy 0.7099767981438515\n",
      "==================================================\n",
      "\n",
      "\n",
      "Simplified decision tree\n",
      "top feature name: exclamation split thresh: <1e-05\n",
      "  right feature name: meter split thresh: <1e-05\n",
      "    right class: 0\n",
      "    left feature name: ampersand split thresh: <1e-05\n",
      "      right class: 0\n",
      "      left class: 1\n",
      "  left feature name: meter split thresh: <1e-05\n",
      "    right class: 0\n",
      "    left feature name: parenthesis split thresh: <1e-05\n",
      "      right class: 0\n",
      "      left class: 0\n",
      "training accuracy: 0.8651196519216824\n",
      "validation accuracy: 0.8289855072463768\n",
      "==================================================\n",
      "\n",
      "\n",
      "random forest\n",
      "training accuracy: 0.8013052936910805\n",
      "validation accuracy: 0.8048309178743961\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # dataset = \"titanic\"\n",
    "    dataset = \"spam\"\n",
    "    params = {\n",
    "        \"max_depth\": 6,\n",
    "        # \"random_state\": 6,\n",
    "        \"min_samples_leaf\": 10,\n",
    "    }\n",
    "    N = 50\n",
    "\n",
    "    if dataset == \"titanic\":\n",
    "        # Load titanic data\n",
    "\n",
    "        path_train = './datasets/titanic/titanic_training.csv'\n",
    "        data = genfromtxt(path_train, delimiter=',', dtype=None)\n",
    "        path_test = './datasets/titanic/titanic_testing_data.csv'\n",
    "        test_data = genfromtxt(path_test, delimiter=',', dtype=None)\n",
    "        y = data[1:, 0]  # label = survived\n",
    "        class_names = [\"Died\", \"Survived\"]\n",
    "\n",
    "        labeled_idx = np.where(y != b'')[0]\n",
    "        y = np.array(y[labeled_idx], dtype=np.int)\n",
    "        print(\"\\n\\nPart (b): preprocessing the titanic dataset\")\n",
    "        X, onehot_features = preprocess(data[1:, 1:], onehot_cols=[1, 5, 7, 8])\n",
    "        X = X[labeled_idx, :]\n",
    "        Z, _ = preprocess(test_data[1:, :], onehot_cols=[1, 5, 7, 8])\n",
    "        assert X.shape[1] == Z.shape[1]\n",
    "        features = list(data[0, 1:]) + onehot_features\n",
    "\n",
    "    elif dataset == \"spam\":\n",
    "        features = [\n",
    "            \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\",\n",
    "            \"creative\", \"height\", \"featured\", \"differ\", \"width\", \"other\",\n",
    "            \"energy\", \"business\", \"message\", \"volumes\", \"revision\", \"path\",\n",
    "            \"meter\", \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
    "            \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \"parenthesis\",\n",
    "            \"square_bracket\", \"ampersand\"\n",
    "        ]\n",
    "        assert len(features) == 32\n",
    "\n",
    "        # Load spam data\n",
    "        path_train = './datasets/spam_data/spam_data.mat'\n",
    "        data = scipy.io.loadmat(path_train)\n",
    "        X = data['training_data']\n",
    "        y = np.squeeze(data['training_labels'])\n",
    "        Z = data['test_data']\n",
    "        class_names = [\"Ham\", \"Spam\"]\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Dataset %s not handled\" % dataset)\n",
    "\n",
    "    print(\"Features\", features)\n",
    "    print(\"Train/test size\", X.shape, Z.shape)\n",
    "\n",
    "    print(\"\\n\\nPart 0: constant classifier\")\n",
    "    print(\"Accuracy\", 1 - np.sum(y) / y.size)\n",
    "\n",
    "    # Basic decision tree\n",
    "    print('==================================================')\n",
    "    print(\"\\n\\nSimplified decision tree\")\n",
    "    dt = DecisionTree(max_depth=3, feature_labels=features)\n",
    "    train, val, train_label, val_label = train_test_split(X, y, test_size=0.2)\n",
    "    dt.fit(train, train_label)\n",
    "    dt.__repr__()\n",
    "    dt = DecisionTree(max_depth=17, feature_labels=features)\n",
    "    train, val, train_label, val_label = train_test_split(X, y, test_size=0.2)\n",
    "    dt.fit(train, train_label)\n",
    "    pred1 = dt.predict(train)\n",
    "    pred2 = dt.predict(val)\n",
    "    print('training accuracy:', sum(pred1 == train_label)/len(train_label))\n",
    "    print('validation accuracy:', sum(pred2 == val_label)/len(val_label))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # random forest\n",
    "    print('==================================================')\n",
    "    print(\"\\n\\nrandom forest\")\n",
    "    dt = RandomForest(params = params, n = N, m = 10)\n",
    "    train, val, train_label, val_label = train_test_split(X, y, test_size=0.2)\n",
    "    dt.fit(train, train_label)\n",
    "    pred1 = dt.predict(train)\n",
    "    pred2 = dt.predict(val)\n",
    "    print('training accuracy:', sum(pred1 == train_label)/len(train_label))\n",
    "    print('validation accuracy:', sum(pred2 == val_label)/len(val_label))\n",
    "    dt.fit(X, y)\n",
    "    pred3 = dt.predict(Z)\n",
    "    results_to_csv1(pred3)\n",
    "\n",
    "    # TODO implement and evaluate remaining parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'validation accuracies as a function of the depth')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_acc = []\n",
    "depth = []\n",
    "for i in range(1, 41):\n",
    "    dt = DecisionTree(max_depth=i, feature_labels=features)\n",
    "    dt.fit(train, train_label)\n",
    "    val_acc += [sum(dt.predict(val) == val_label)/len(val_label)]\n",
    "    depth += [i]\n",
    "plt.plot(depth, val_acc)\n",
    "plt.xlabel('depth')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.title('validation accuracies as a function of the depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "    if val_acc[i] == max(val_acc):\n",
    "        print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaoliang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/yaoliang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Part (b): preprocessing the titanic dataset\n",
      "Features [b'pclass', b'sex', b'age', b'sibsp', b'parch', b'ticket', b'fare', b'cabin', b'embarked', b'male', b'female', b'S', b'C', b'Q']\n",
      "Train/test size (999, 14) (310, 14)\n",
      "\n",
      "\n",
      "Part 0: constant classifier\n",
      "Accuracy 0.6136136136136137\n",
      "==================================================\n",
      "\n",
      "\n",
      "Simplified decision tree\n",
      "top feature name: b'male' split thresh: <1e-05\n",
      "  right feature name: b'pclass' split thresh: <1.00001\n",
      "    right feature name: b'sibsp' split thresh: <2.6666700000000003\n",
      "      right class: 0\n",
      "      left class: 0\n",
      "    left feature name: b'fare' split thresh: <284.6273322222222\n",
      "      right class: 1\n",
      "      left class: 0\n",
      "  left feature name: b'pclass' split thresh: <2.11111\n",
      "    right feature name: b'fare' split thresh: <27.816669999999995\n",
      "      right class: 0\n",
      "      left class: 1\n",
      "    left feature name: b'S' split thresh: <1e-05\n",
      "      right class: 1\n",
      "      left class: 1\n",
      "training accuracy: 0.83729662077597\n",
      "validation accuracy: 0.805\n",
      "==================================================\n",
      "\n",
      "\n",
      "random forest\n",
      "training accuracy: 0.853566958698373\n",
      "validation accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # dataset = \"titanic\"\n",
    "    dataset = \"titanic\"\n",
    "    params = {\n",
    "        \"max_depth\": 6,\n",
    "        # \"random_state\": 6,\n",
    "        \"min_samples_leaf\": 10,\n",
    "    }\n",
    "    N = 50\n",
    "\n",
    "    if dataset == \"titanic\":\n",
    "        # Load titanic data\n",
    "\n",
    "        path_train = './datasets/titanic/titanic_training.csv'\n",
    "        data = genfromtxt(path_train, delimiter=',', dtype=None)\n",
    "        path_test = './datasets/titanic/titanic_testing_data.csv'\n",
    "        test_data = genfromtxt(path_test, delimiter=',', dtype=None)\n",
    "        y = data[1:, 0]  # label = survived\n",
    "        class_names = [\"Died\", \"Survived\"]\n",
    "\n",
    "        labeled_idx = np.where(y != b'')[0]\n",
    "        y = np.array(y[labeled_idx], dtype=np.int)\n",
    "        print(\"\\n\\nPart (b): preprocessing the titanic dataset\")\n",
    "        X, onehot_features = preprocess(data[1:, 1:], onehot_cols=[1, 5, 7, 8])\n",
    "        X = X[labeled_idx, :]\n",
    "        Z, _ = preprocess(test_data[1:, :], onehot_cols=[1, 5, 7, 8])\n",
    "        assert X.shape[1] == Z.shape[1]\n",
    "        features = list(data[0, 1:]) + onehot_features\n",
    "\n",
    "    elif dataset == \"spam\":\n",
    "        features = [\n",
    "            \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\",\n",
    "            \"creative\", \"height\", \"featured\", \"differ\", \"width\", \"other\",\n",
    "            \"energy\", \"business\", \"message\", \"volumes\", \"revision\", \"path\",\n",
    "            \"meter\", \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
    "            \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \"parenthesis\",\n",
    "            \"square_bracket\", \"ampersand\"\n",
    "        ]\n",
    "        assert len(features) == 32\n",
    "\n",
    "        # Load spam data\n",
    "        path_train = './datasets/spam_data/spam_data.mat'\n",
    "        data = scipy.io.loadmat(path_train)\n",
    "        X = data['training_data']\n",
    "        y = np.squeeze(data['training_labels'])\n",
    "        Z = data['test_data']\n",
    "        class_names = [\"Ham\", \"Spam\"]\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Dataset %s not handled\" % dataset)\n",
    "\n",
    "    print(\"Features\", features)\n",
    "    print(\"Train/test size\", X.shape, Z.shape)\n",
    "\n",
    "    print(\"\\n\\nPart 0: constant classifier\")\n",
    "    print(\"Accuracy\", 1 - np.sum(y) / y.size)\n",
    "\n",
    "    # Basic decision tree\n",
    "    print('==================================================')\n",
    "    print(\"\\n\\nSimplified decision tree\")\n",
    "    dt = DecisionTree(max_depth=3, feature_labels=features)\n",
    "    train, val, train_label, val_label = train_test_split(X, y, test_size=0.2)\n",
    "    dt.fit(train, train_label)\n",
    "    dt.__repr__()\n",
    "    dt = DecisionTree(max_depth=6, feature_labels=features)\n",
    "    train, val, train_label, val_label = train_test_split(X, y, test_size=0.2)\n",
    "    dt.fit(train, train_label)\n",
    "    pred1 = dt.predict(train)\n",
    "    pred2 = dt.predict(val)\n",
    "    print('training accuracy:', sum(pred1 == train_label)/len(train_label))\n",
    "    print('validation accuracy:', sum(pred2 == val_label)/len(val_label))\n",
    "    \n",
    "    # random forest\n",
    "    print('==================================================')\n",
    "    print(\"\\n\\nrandom forest\")\n",
    "    dt = RandomForest(params = params, n = N, m = 5)\n",
    "    train, val, train_label, val_label = train_test_split(X, y, test_size=0.2)\n",
    "    dt.fit(train, train_label)\n",
    "    pred1 = dt.predict(train)\n",
    "    pred2 = dt.predict(val)\n",
    "    print('training accuracy:', sum(pred1 == train_label)/len(train_label))\n",
    "    print('validation accuracy:', sum(pred2 == val_label)/len(val_label))\n",
    "    dt.fit(X, y)\n",
    "    pred3 = dt.predict(Z)\n",
    "    results_to_csv2(pred3)\n",
    "\n",
    "    # TODO implement and evaluate remaining parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_csv1(y_test):\n",
    "    y_test = y_test.astype(int)\n",
    "    df = pd.DataFrame({'Category': y_test})\n",
    "    df.index += 1  # Ensures that the index starts at 1. \n",
    "    df.to_csv('submission1.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_csv2(y_test):\n",
    "    y_test = y_test.astype(int)\n",
    "    df = pd.DataFrame({'Category': y_test})\n",
    "    df.index += 1  # Ensures that the index starts at 1. \n",
    "    df.to_csv('submission2.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Name: Yao Liang, Kaggle Score: SPAM: 0.75112, TITANIC: 0.78629."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
